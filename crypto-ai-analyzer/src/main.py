"""
Point d'entr√©e principal de l'application d'analyse de crypto-monnaies.
"""
import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# Ajouter le r√©pertoire parent au PATH pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.collectors.api_collector import ApiCollector
from data.collectors.yfinance_collector import YFinanceCollector
from data.storage.database import Database
from analysis.preprocessing import clean_data, normalize_data, prepare_time_series, split_data
from analysis.indicators import add_all_indicators
from models.training import Training
from models.prediction import Prediction
import config

def collect_data(symbols=None, days=365, use_api=True, save_to_db=True):
    """
    Collecte des donn√©es historiques pour les crypto-monnaies sp√©cifi√©es.
    
    Args:
        symbols (list): Liste des symboles des crypto-monnaies.
        days (int): Nombre de jours d'historique √† r√©cup√©rer.
        use_api (bool): Si True, utilise l'API, sinon essaie de r√©cup√©rer de la DB.
        save_to_db (bool): Si True, sauvegarde les donn√©es dans la base de donn√©es.
        
    Returns:
        dict: Dictionnaire de DataFrames contenant les donn√©es par symbole.
    """
    if symbols is None:
        symbols = config.CRYPTO_SYMBOLS
    
    data_dict = {}
    
    # Initialiser le collecteur alternatif (YFinance) qui est plus fiable
    print("üîß Utilisation de Yahoo Finance pour les donn√©es...")
    yf_collector = YFinanceCollector()
    
    # Initialiser aussi l'API collector comme fallback
    api_url = config.API_ENDPOINTS[config.DEFAULT_API]
    api_collector = ApiCollector(api_url=api_url)
    
    # Initialiser la base de donn√©es
    db = Database(db_url=config.DATABASE_URL)
    
    for symbol in symbols:
        print(f"Collecte des donn√©es pour {symbol}...")
        
        try:
            if use_api:
                # Essayer d'abord YFinance (plus fiable)
                try:
                    data = yf_collector.fetch_data(symbol, days=days)
                    if data is not None and not data.empty:
                        print(f"  ‚úì {len(data)} points de donn√©es collect√©s depuis Yahoo Finance")
                        data_dict[symbol] = data
                        continue
                except Exception as yf_error:
                    print(f"  ‚ö†Ô∏è Yahoo Finance √©chec, essai avec l'API principale")
                
                # Fallback vers l'API principale
                try:
                    data = api_collector.fetch_data(symbol, days=365)  # Limit√© √† 365 jours
                    if data is not None and not data.empty:
                        print(f"  ‚úì {len(data)} points de donn√©es collect√©s depuis l'API")
                        data_dict[symbol] = data
                    else:
                        print(f"  ‚úó Aucune donn√©e re√ßue de l'API pour {symbol}")
                except Exception as api_error:
                    print(f"  ‚úó Erreur API: {api_error}")
            else:
                # Essayer de charger depuis la DB
                try:
                    data = db.get_price_data(symbol, days=days)
                    if data is not None and not data.empty:
                        print(f"  ‚úì {len(data)} points de donn√©es charg√©s depuis la DB")
                        data_dict[symbol] = data
                    else:
                        print(f"  ‚úó Aucune donn√©e trouv√©e en DB pour {symbol}")
                except Exception:
                    print(f"  ‚úó Erreur lors de la lecture de la DB pour {symbol}")
                    
        except Exception as e:
            print(f"  ‚úó Erreur lors de la collecte pour {symbol}: {e}")
            continue
    
    return data_dict

def preprocess_data(data_dict):
    """
    Pr√©traite les donn√©es collect√©es en ajoutant des indicateurs techniques
    et en nettoyant les donn√©es.
    
    Args:
        data_dict (dict): Dictionnaire de DataFrames de donn√©es brutes.
        
    Returns:
        dict: Dictionnaire de DataFrames pr√©trait√©s.
    """
    processed_data = {}
    
    for symbol, df in data_dict.items():
        print(f"Pr√©traitement des donn√©es pour {symbol}...")
        
        # Nettoyer les donn√©es
        df_clean = clean_data(df)
        print(f"  ‚úì Donn√©es nettoy√©es: {len(df_clean)} entr√©es")
        
        # Ajouter les indicateurs techniques
        df_indicators = add_all_indicators(df_clean)
        print(f"  ‚úì Indicateurs techniques ajout√©s")
        
        # Supprimer les lignes avec des NaN (les premiers jours n'ont pas tous les indicateurs)
        df_indicators = df_indicators.dropna()
        print(f"  ‚úì Lignes avec valeurs manquantes supprim√©es: {len(df_indicators)} entr√©es")
        
        processed_data[symbol] = df_indicators
    
    return processed_data

def train_models(data_dict, window_size=60, forecast_horizon=1):
    """
    Entra√Æne des mod√®les de pr√©diction pour chaque symbole.
    """
    models = {}
    
    for symbol, df in data_dict.items():
        print(f"Entra√Ænement du mod√®le pour {symbol}...")
        
        # √âtape 1: S'assurer que toutes les colonnes sont num√©riques
        numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
        df_numeric = df[numeric_columns].copy()
        
        # √âtape 2: V√©rifier qu'il ne reste pas de NaN
        df_numeric = df_numeric.fillna(0)
        print(f"  ‚úì Donn√©es nettoy√©es: {len(df_numeric)} entr√©es avec {len(numeric_columns)} caract√©ristiques num√©riques")
        
        # √âtape 3: Normaliser les donn√©es
        df_norm = normalize_data(df_numeric)
        print(f"  ‚úì Donn√©es normalis√©es")
        
        # √âtape 4: Pr√©parer les donn√©es pour l'entra√Ænement
        X, y = prepare_time_series(df_norm, 'price', window_size, forecast_horizon)
        
        # √âtape 5: Convertir explicitement en float32
        X = X.astype(np.float32)
        y = y.astype(np.float32)
        print(f"  ‚úì Donn√©es de s√©ries temporelles pr√©par√©es: {len(X)} √©chantillons")
        
        if len(X) == 0:
            print(f"  ‚úó Pas assez de donn√©es pour {symbol}, passage au suivant")
            continue
        
        # √âtape 6: Diviser les donn√©es en ensembles d'entra√Ænement et de test
        X_train, X_test, y_train, y_test = split_data(X, y, train_ratio=0.8)
        print(f"  ‚úì Donn√©es divis√©es: {len(X_train)} √©chantillons d'entra√Ænement, {len(X_test)} √©chantillons de test")
        
        # √âtape 7: Cr√©er et entra√Æner le mod√®le
        trainer = Training(model=None, data=(X_train, y_train))
        model = trainer.create_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))
        
        # Configurer l'entra√Ænement
        batch_size = 32
        
        # Ajouter early stopping pour √©viter le surajustement
        from tensorflow.keras.callbacks import EarlyStopping
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        
        history = model.fit(
            X_train, y_train,
            epochs=100,  # Plus d'√©poques, mais avec early stopping
            batch_size=batch_size,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )
        print(f"  ‚úì Mod√®le entra√Æn√©")
        
        # Sauvegarder le mod√®le et les donn√©es
        models[symbol] = {
            'model': model,
            'data': {
                'X_test': X_test,
                'y_test': y_test,
                'dates': df.index[-len(X_test):]
            }
        }
    
    return models

def generate_predictions(models, data_dict):
    """
    G√©n√®re des pr√©dictions pour chaque mod√®le.
    
    Args:
        models (dict): Dictionnaire des mod√®les entra√Æn√©s
        data_dict (dict): Dictionnaire des donn√©es
        
    Returns:
        dict: Pr√©dictions pour chaque symbole
    """
    predictions = {}
    
    for symbol, model_data in models.items():
        print(f"G√©n√©ration des pr√©dictions pour {symbol}...")
        
        model = model_data['model']
        X_test = model_data['data']['X_test']
        y_test = model_data['data']['y_test']
        
        # Cr√©er un objet de pr√©diction
        predictor = Prediction(model=model)
        
        # G√©n√©rer les pr√©dictions
        y_pred = predictor.predict(X_test)
        
        predictions[symbol] = {
            'predictions': y_pred,
            'actual': y_test,
            'dates': model_data['data']['dates']
        }
        
        print(f"  ‚úì Pr√©dictions g√©n√©r√©es pour {symbol}")
    
    return predictions

def visualize_results(models, data_dict, predictions):
    """
    Visualise les r√©sultats des pr√©dictions.
    
    Args:
        models (dict): Dictionnaire des mod√®les entra√Æn√©s
        data_dict (dict): Dictionnaire des donn√©es
        predictions (dict): Dictionnaire des pr√©dictions
    """
    # Cr√©er le dossier outputs s'il n'existe pas
    outputs_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "outputs")
    os.makedirs(outputs_dir, exist_ok=True)
    
    for symbol in predictions.keys():
        print(f"Visualisation des r√©sultats pour {symbol}...")
        
        model_data = models[symbol]
        model = model_data['model']
        X_test = model_data['data']['X_test']
        y_test = model_data['data']['y_test']
        dates = model_data['data']['dates']
        
        # Cr√©er un objet de pr√©diction
        predictor = Prediction(model=model)
        
        # √âvaluer le mod√®le
        metrics = predictor.evaluate(X_test, y_test)
        print(f"  ‚úì M√©triques pour {symbol}:")
        print(f"    - RMSE: {metrics['rmse']:.2f}")
        print(f"    - MAE: {metrics['mae']:.2f}")
        print(f"    - MAPE: {metrics['mape']:.2f}%")
        print(f"    - R¬≤: {metrics['r2']:.4f}")
        
        # Tracer les pr√©dictions
        plt_obj = predictor.plot_predictions(X_test, y_test, dates, 
                                           title=f"Pr√©dictions vs R√©alit√© pour {symbol}")
        
        # Sauvegarder le graphique
        output_path = os.path.join(outputs_dir, f"{symbol}_predictions.png")
        plt_obj.savefig(output_path)
        print(f"  ‚úì Graphique sauvegard√© : {output_path}")
        plt_obj.close()

def main():
    """Fonction principale pour lancer l'analyse compl√®te"""
    print("üöÄ Lancement du Crypto AI Analyzer")
    print("=" * 50)
    
    try:
        # 1. Collecte des donn√©es
        print("üìä Collecte des donn√©es...")
        data_dict = collect_data()
        
        if not data_dict:
            print("‚ùå Aucune donn√©e collect√©e. Arr√™t du programme.")
            return 1
        
        # 2. Pr√©traitement des donn√©es
        print("üîß Pr√©traitement des donn√©es...")
        processed_data = preprocess_data(data_dict)
        
        if not processed_data:
            print("‚ùå Aucune donn√©e pr√©trait√©e. Arr√™t du programme.")
            return 1
        
        # 3. Entra√Ænement des mod√®les
        print("ü§ñ Entra√Ænement des mod√®les...")
        models = train_models(processed_data)
        
        if not models:
            print("‚ùå Aucun mod√®le entra√Æn√©. Arr√™t du programme.")
            return 1
        
        # 4. G√©n√©ration des pr√©dictions
        print("üîÆ G√©n√©ration des pr√©dictions...")
        predictions = generate_predictions(models, processed_data)
        
        # 5. Visualisation des r√©sultats
        print("üìà G√©n√©ration des graphiques...")
        visualize_results(models, processed_data, predictions)
        
        print("‚úÖ Analyse termin√©e avec succ√®s !")
        print("üìÅ V√©rifiez le dossier 'outputs/' pour les r√©sultats")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution : {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
