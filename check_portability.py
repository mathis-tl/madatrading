#!/usr/bin/env python3
"""
Script de vÃ©rification des imports et de la structure du projet
pour s'assurer de la portabilitÃ©
"""

import os
import sys
import importlib
from pathlib import Path

def test_basic_imports():
    """Test des imports de base Python"""
    print("ğŸ§ª Test des imports de base...")
    basic_modules = [
        ('os', 'SystÃ¨me d\'exploitation'),
        ('sys', 'SystÃ¨me Python'),
        ('pathlib', 'Manipulation de chemins'),
        ('json', 'Manipulation JSON'),
        ('datetime', 'Gestion des dates'),
        ('sqlite3', 'Base de donnÃ©es SQLite')
    ]
    
    success = 0
    for module, desc in basic_modules:
        try:
            importlib.import_module(module)
            print(f"  âœ… {module} - {desc}")
            success += 1
        except ImportError as e:
            print(f"  âŒ {module} - Erreur: {e}")
    
    return success == len(basic_modules)

def test_third_party_imports():
    """Test des imports de bibliothÃ¨ques tierces"""
    print("\nğŸ“¦ Test des bibliothÃ¨ques tierces...")
    third_party = [
        ('numpy', 'Calculs numÃ©riques'),
        ('pandas', 'Manipulation de donnÃ©es'),
        ('matplotlib', 'Graphiques'),
        ('sklearn', 'Machine Learning'),
        ('requests', 'RequÃªtes HTTP'),
        ('yfinance', 'DonnÃ©es financiÃ¨res')
    ]
    
    success = 0
    optional_success = 0
    optional_modules = [('tensorflow', 'Deep Learning (optionnel)')]
    
    for module, desc in third_party:
        try:
            importlib.import_module(module)
            print(f"  âœ… {module} - {desc}")
            success += 1
        except ImportError as e:
            print(f"  âŒ {module} - Erreur: {e}")
    
    # Test des modules optionnels
    for module, desc in optional_modules:
        try:
            importlib.import_module(module)
            print(f"  âœ… {module} - {desc}")
            optional_success += 1
        except ImportError as e:
            print(f"  âš ï¸ {module} - {desc} - Pas installÃ© (normal)")
    
    return success >= len(third_party) - 1  # On accepte 1 Ã©chec

def test_project_structure():
    """Test de la structure du projet"""
    print("\nğŸ“ Test de la structure du projet...")
    
    required_files = [
        'launcher.py',
        'requirements.txt',
        'README.md',
        'install.py',
        '.env.example',
        'IA_madatrading.py'
    ]
    
    required_dirs = [
        'crypto-ai-analyzer',
        'crypto-ai-analyzer/src',
        'outputs'
    ]
    
    success = 0
    
    print("  Fichiers requis:")
    for file in required_files:
        if os.path.exists(file):
            print(f"    âœ… {file}")
            success += 1
        else:
            print(f"    âŒ {file} - Manquant")
    
    print("  Dossiers requis:")
    for directory in required_dirs:
        if os.path.exists(directory):
            print(f"    âœ… {directory}")
            success += 1
        else:
            print(f"    âŒ {directory} - Manquant")
    
    return success == len(required_files) + len(required_dirs)

def test_crypto_ai_imports():
    """Test des imports du module crypto-ai-analyzer"""
    print("\nğŸ¤– Test des imports crypto-ai-analyzer...")
    
    # Ajouter le chemin vers le module
    crypto_path = os.path.join(os.getcwd(), 'crypto-ai-analyzer', 'src')
    if crypto_path not in sys.path:
        sys.path.insert(0, crypto_path)
    
    test_imports = [
        ('config', 'Configuration'),
        ('data.collectors.api_collector', 'Collecteur API'),
        ('data.storage.database', 'Base de donnÃ©es'),
        ('analysis.preprocessing', 'PrÃ©traitement'),
        ('analysis.indicators', 'Indicateurs techniques'),
        ('models.training', 'EntraÃ®nement'),
        ('models.prediction', 'PrÃ©diction')
    ]
    
    success = 0
    for module, desc in test_imports:
        try:
            importlib.import_module(module)
            print(f"  âœ… {module} - {desc}")
            success += 1
        except ImportError as e:
            print(f"  âŒ {module} - {desc} - Erreur: {e}")
    
    return success >= len(test_imports) - 2  # On accepte 2 Ã©checs

def test_launchers():
    """Test que les scripts de lancement existent et sont exÃ©cutables"""
    print("\nğŸš€ Test des scripts de lancement...")
    
    launchers = [
        ('launcher.py', 'Menu principal'),
        ('IA_madatrading.py', 'Script simple'),
        ('crypto-ai-analyzer/src/main.py', 'Module IA avancÃ©')
    ]
    
    success = 0
    for script, desc in launchers:
        if os.path.exists(script):
            # VÃ©rifier que le fichier n'est pas vide
            with open(script, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content and ('def ' in content or 'import ' in content):
                    print(f"  âœ… {script} - {desc}")
                    success += 1
                else:
                    print(f"  âš ï¸ {script} - {desc} - Fichier vide ou invalide")
        else:
            print(f"  âŒ {script} - {desc} - Manquant")
    
    return success == len(launchers)

def generate_summary_report():
    """GÃ©nÃ¨re un rapport de rÃ©sumÃ©"""
    print("\nğŸ“‹ RAPPORT DE PORTABILITÃ‰")
    print("=" * 50)
    
    tests = [
        ("Imports de base Python", test_basic_imports),
        ("BibliothÃ¨ques tierces", test_third_party_imports),
        ("Structure du projet", test_project_structure),
        ("Imports crypto-ai-analyzer", test_crypto_ai_imports),
        ("Scripts de lancement", test_launchers)
    ]
    
    results = []
    total_score = 0
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
            total_score += 1 if result else 0
        except Exception as e:
            print(f"Erreur lors du test {test_name}: {e}")
            results.append((test_name, False))
    
    print(f"\nğŸ† RÃ‰SULTATS FINAUX:")
    for test_name, result in results:
        status = "âœ… SUCCÃˆS" if result else "âŒ Ã‰CHEC"
        print(f"  {status} - {test_name}")
    
    score_percentage = (total_score / len(tests)) * 100
    print(f"\nğŸ“Š Score total: {total_score}/{len(tests)} ({score_percentage:.1f}%)")
    
    if score_percentage >= 80:
        print("ğŸ‰ EXCELLENT! Le projet est prÃªt pour la portabilitÃ©!")
        return True
    elif score_percentage >= 60:
        print("âš ï¸ CORRECT. Quelques amÃ©liorations recommandÃ©es.")
        return True
    else:
        print("âŒ PROBLÃˆMES DÃ‰TECTÃ‰S. Corrections nÃ©cessaires.")
        return False

def main():
    """Fonction principale de vÃ©rification"""
    print("ğŸ” VÃ‰RIFICATION DE LA PORTABILITÃ‰ DU PROJET MADATRADING")
    print("=" * 60)
    print(f"ğŸ“ RÃ©pertoire de travail: {os.getcwd()}")
    print(f"ğŸ Version Python: {sys.version}")
    print(f"ğŸ’» Plateforme: {sys.platform}")
    
    success = generate_summary_report()
    
    if success:
        print("\nâœ… Le projet est prÃªt Ã  Ãªtre partagÃ© sur GitHub!")
        print("\nğŸ“ Instructions pour l'utilisateur final:")
        print("1. git clone ou tÃ©lÃ©charger le ZIP")
        print("2. python install.py")
        print("3. python launcher.py")
    else:
        print("\nâŒ Des corrections sont nÃ©cessaires avant le partage.")
        print("\nğŸ› ï¸ Actions recommandÃ©es:")
        print("- ExÃ©cuter: python install.py")
        print("- VÃ©rifier les imports manquants")
        print("- Relancer ce script de vÃ©rification")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
